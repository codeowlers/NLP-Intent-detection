{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from algorithms import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dsl_data/development.csv')\n",
    "df_eval = pd.read_csv('dsl_data/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# condition = (df['Current language used for work/school'] == np.unique(df_eval['Current language used for work/school'].values)[0]) & (df['First Language spoken'] == np.unique(df_eval['First Language spoken'].values)[0]) & (df['Self-reported fluency level '] == np.unique(df_eval['Self-reported fluency level '].values)[0])\n",
    "# df = df.loc[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cols = ['Id','Self-reported fluency level ', 'First Language spoken', 'Current language used for work/school']\n",
    "df.drop(columns=cols,inplace=True)\n",
    "df_eval.drop(columns=cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['intent'] = df['action'] + df['object']\n",
    "dict = {}\n",
    "for i, el in enumerate(df['intent'].unique()):\n",
    "    dict[el] = i\n",
    "\n",
    "df['intent'] = df['intent'].apply(lambda x: dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>speakerId</th>\n",
       "      <th>male</th>\n",
       "      <th>41-65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsl_data/audio/speakers/NgQEvO2x7Vh3xy2xz/f53c...</td>\n",
       "      <td>NgQEvO2x7Vh3xy2xz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsl_data/audio/speakers/k5bqyxx2lzIbrlg9/1d5f8...</td>\n",
       "      <td>k5bqyxx2lzIbrlg9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsl_data/audio/speakers/7B4XmNppyrCK977p/1c0d5...</td>\n",
       "      <td>7B4XmNppyrCK977p</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsl_data/audio/speakers/k5bqyxx2lzIbrlg9/275c3...</td>\n",
       "      <td>k5bqyxx2lzIbrlg9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsl_data/audio/speakers/V4ZbwLm9G5irobWn/b7c7a...</td>\n",
       "      <td>V4ZbwLm9G5irobWn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>dsl_data/audio/speakers/oOK5kxoW7dskMbaK/02f5d...</td>\n",
       "      <td>oOK5kxoW7dskMbaK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>dsl_data/audio/speakers/oOK5kxoW7dskMbaK/87191...</td>\n",
       "      <td>oOK5kxoW7dskMbaK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>dsl_data/audio/speakers/ppymZZDb2Bf4NQnE/f2a9e...</td>\n",
       "      <td>ppymZZDb2Bf4NQnE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>dsl_data/audio/speakers/aokxBz9LxXHzZzay/f347b...</td>\n",
       "      <td>aokxBz9LxXHzZzay</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>dsl_data/audio/speakers/NgQEvO2x7Vh3xy2xz/aa56...</td>\n",
       "      <td>NgQEvO2x7Vh3xy2xz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path          speakerId  \\\n",
       "0     dsl_data/audio/speakers/NgQEvO2x7Vh3xy2xz/f53c...  NgQEvO2x7Vh3xy2xz   \n",
       "1     dsl_data/audio/speakers/k5bqyxx2lzIbrlg9/1d5f8...   k5bqyxx2lzIbrlg9   \n",
       "2     dsl_data/audio/speakers/7B4XmNppyrCK977p/1c0d5...   7B4XmNppyrCK977p   \n",
       "3     dsl_data/audio/speakers/k5bqyxx2lzIbrlg9/275c3...   k5bqyxx2lzIbrlg9   \n",
       "4     dsl_data/audio/speakers/V4ZbwLm9G5irobWn/b7c7a...   V4ZbwLm9G5irobWn   \n",
       "...                                                 ...                ...   \n",
       "1450  dsl_data/audio/speakers/oOK5kxoW7dskMbaK/02f5d...   oOK5kxoW7dskMbaK   \n",
       "1451  dsl_data/audio/speakers/oOK5kxoW7dskMbaK/87191...   oOK5kxoW7dskMbaK   \n",
       "1452  dsl_data/audio/speakers/ppymZZDb2Bf4NQnE/f2a9e...   ppymZZDb2Bf4NQnE   \n",
       "1453  dsl_data/audio/speakers/aokxBz9LxXHzZzay/f347b...   aokxBz9LxXHzZzay   \n",
       "1454  dsl_data/audio/speakers/NgQEvO2x7Vh3xy2xz/aa56...  NgQEvO2x7Vh3xy2xz   \n",
       "\n",
       "      male  41-65  \n",
       "0        1      0  \n",
       "1        1      0  \n",
       "2        1      1  \n",
       "3        1      0  \n",
       "4        0      1  \n",
       "...    ...    ...  \n",
       "1450     0      0  \n",
       "1451     0      0  \n",
       "1452     0      1  \n",
       "1453     0      0  \n",
       "1454     1      0  \n",
       "\n",
       "[1455 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['gender', 'ageRange']\n",
    "one_hot_encode_columns(df,cols)\n",
    "one_hot_encode_columns(df_eval,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "audio_feature_extraction(df)\n",
    "audio_feature_extraction(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def trim_audio(row):\n",
    "    data = row['data']\n",
    "    trimmed_data, index = librosa.effects.trim(data, top_db=20, frame_length=512, hop_length=64)\n",
    "    return trimmed_data\n",
    "\n",
    "df['data'] = df.apply(trim_audio, axis=1)\n",
    "df_eval['data'] = df_eval.apply(trim_audio, axis=1)\n",
    "\n",
    "df['data'] = df['data'].apply(lambda x: np.hstack([x[part[0]:part[-1]] for part in librosa.effects.split(x, top_db=30)]))\n",
    "df_eval['data'] = df_eval['data'].apply(lambda x: np.hstack([x[part[0]:part[-1]] for part in librosa.effects.split(x, top_db=30)]))\n",
    "def pad_audio(row):\n",
    "    audio = row['data']\n",
    "    sr = row['rate']\n",
    "    max_length = int(30 * sr) # 30 seconds * sampling rate\n",
    "    return np.pad(audio, (0, max_length - len(audio)), mode='constant', constant_values=0)\n",
    "\n",
    "df['data'] = df.apply(pad_audio, axis=1)\n",
    "df_eval['data'] = df_eval.apply(pad_audio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>speakerId</th>\n",
       "      <th>action</th>\n",
       "      <th>object</th>\n",
       "      <th>gender</th>\n",
       "      <th>ageRange</th>\n",
       "      <th>intent</th>\n",
       "      <th>data</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/0a312...</td>\n",
       "      <td>2BqVo8kVB2Skwgyb</td>\n",
       "      <td>change language</td>\n",
       "      <td>none</td>\n",
       "      <td>female</td>\n",
       "      <td>22-40</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004102989, 0.0017110795, 0.0046248036, -0....</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/0ee42...</td>\n",
       "      <td>2BqVo8kVB2Skwgyb</td>\n",
       "      <td>activate</td>\n",
       "      <td>music</td>\n",
       "      <td>female</td>\n",
       "      <td>22-40</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0034481208, -0.0040454636, -0.0046446496, ...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/1d9f3...</td>\n",
       "      <td>2BqVo8kVB2Skwgyb</td>\n",
       "      <td>deactivate</td>\n",
       "      <td>lights</td>\n",
       "      <td>female</td>\n",
       "      <td>22-40</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0014983321, 0.0014417854, 0.0013267061, 0.0...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/269fc...</td>\n",
       "      <td>2BqVo8kVB2Skwgyb</td>\n",
       "      <td>increase</td>\n",
       "      <td>volume</td>\n",
       "      <td>female</td>\n",
       "      <td>22-40</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.0074363947, -0.007070067, -0.005553694, -0...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/5bbda...</td>\n",
       "      <td>2BqVo8kVB2Skwgyb</td>\n",
       "      <td>increase</td>\n",
       "      <td>volume</td>\n",
       "      <td>female</td>\n",
       "      <td>22-40</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.00081694237, -0.0005666799, -0.00014418755...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>dsl_data/audio/speakers/vnljypgejkINbBAY/4fb3d...</td>\n",
       "      <td>vnljypgejkINbBAY</td>\n",
       "      <td>decrease</td>\n",
       "      <td>volume</td>\n",
       "      <td>male</td>\n",
       "      <td>22-40</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0013669498, 0.0024509765, 0.0036058861, 0.0...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>dsl_data/audio/speakers/vnljypgejkINbBAY/59e6a...</td>\n",
       "      <td>vnljypgejkINbBAY</td>\n",
       "      <td>deactivate</td>\n",
       "      <td>lights</td>\n",
       "      <td>male</td>\n",
       "      <td>22-40</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.001144933, -0.013419567, 0.005848511, 0.01...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>dsl_data/audio/speakers/vnljypgejkINbBAY/5c81c...</td>\n",
       "      <td>vnljypgejkINbBAY</td>\n",
       "      <td>deactivate</td>\n",
       "      <td>lights</td>\n",
       "      <td>male</td>\n",
       "      <td>22-40</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0013577347, 0.015522823, 0.023896402, 0.01...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9852</th>\n",
       "      <td>dsl_data/audio/speakers/vnljypgejkINbBAY/5ef42...</td>\n",
       "      <td>vnljypgejkINbBAY</td>\n",
       "      <td>deactivate</td>\n",
       "      <td>lights</td>\n",
       "      <td>male</td>\n",
       "      <td>22-40</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0047846185, -0.0029887287, -0.0042724935, ...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>dsl_data/audio/speakers/vnljypgejkINbBAY/61b7a...</td>\n",
       "      <td>vnljypgejkINbBAY</td>\n",
       "      <td>increase</td>\n",
       "      <td>volume</td>\n",
       "      <td>male</td>\n",
       "      <td>22-40</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0434565, 0.04046881, 0.037868533, 0.0355861...</td>\n",
       "      <td>22050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9854 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path         speakerId  \\\n",
       "0     dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/0a312...  2BqVo8kVB2Skwgyb   \n",
       "1     dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/0ee42...  2BqVo8kVB2Skwgyb   \n",
       "2     dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/1d9f3...  2BqVo8kVB2Skwgyb   \n",
       "3     dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/269fc...  2BqVo8kVB2Skwgyb   \n",
       "4     dsl_data/audio/speakers/2BqVo8kVB2Skwgyb/5bbda...  2BqVo8kVB2Skwgyb   \n",
       "...                                                 ...               ...   \n",
       "9849  dsl_data/audio/speakers/vnljypgejkINbBAY/4fb3d...  vnljypgejkINbBAY   \n",
       "9850  dsl_data/audio/speakers/vnljypgejkINbBAY/59e6a...  vnljypgejkINbBAY   \n",
       "9851  dsl_data/audio/speakers/vnljypgejkINbBAY/5c81c...  vnljypgejkINbBAY   \n",
       "9852  dsl_data/audio/speakers/vnljypgejkINbBAY/5ef42...  vnljypgejkINbBAY   \n",
       "9853  dsl_data/audio/speakers/vnljypgejkINbBAY/61b7a...  vnljypgejkINbBAY   \n",
       "\n",
       "               action  object  gender ageRange  intent  \\\n",
       "0     change language    none  female    22-40       0   \n",
       "1            activate   music  female    22-40       1   \n",
       "2          deactivate  lights  female    22-40       2   \n",
       "3            increase  volume  female    22-40       3   \n",
       "4            increase  volume  female    22-40       3   \n",
       "...               ...     ...     ...      ...     ...   \n",
       "9849         decrease  volume    male    22-40       4   \n",
       "9850       deactivate  lights    male    22-40       2   \n",
       "9851       deactivate  lights    male    22-40       2   \n",
       "9852       deactivate  lights    male    22-40       2   \n",
       "9853         increase  volume    male    22-40       3   \n",
       "\n",
       "                                                   data   rate  \n",
       "0     [-0.004102989, 0.0017110795, 0.0046248036, -0....  22050  \n",
       "1     [-0.0034481208, -0.0040454636, -0.0046446496, ...  22050  \n",
       "2     [0.0014983321, 0.0014417854, 0.0013267061, 0.0...  22050  \n",
       "3     [-0.0074363947, -0.007070067, -0.005553694, -0...  22050  \n",
       "4     [-0.00081694237, -0.0005666799, -0.00014418755...  22050  \n",
       "...                                                 ...    ...  \n",
       "9849  [0.0013669498, 0.0024509765, 0.0036058861, 0.0...  22050  \n",
       "9850  [-0.001144933, -0.013419567, 0.005848511, 0.01...  22050  \n",
       "9851  [-0.0013577347, 0.015522823, 0.023896402, 0.01...  22050  \n",
       "9852  [-0.0047846185, -0.0029887287, -0.0042724935, ...  22050  \n",
       "9853  [0.0434565, 0.04046881, 0.037868533, 0.0355861...  22050  \n",
       "\n",
       "[9854 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = df['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_columns = ['action', 'object', 'intent']\n",
    "df.drop(columns = new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_spectrogram(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    spectrograms = []\n",
    "    for data in dataframe['data']:\n",
    "\n",
    "        # Compute the spectrogram\n",
    "        spectrogram = np.abs(librosa.stft(data))\n",
    "\n",
    "        # Split the spectrogram into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(spectrogram, n_chunks)\n",
    "\n",
    "        # Append the chunks to the list of spectrograms\n",
    "ograms.append(chunks)\n",
    "\n",
    "    # Add the spectrogram chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_spectrogram_\" + str(i)] = [np.mean(chunk[i]) for chunk in spectrograms]\n",
    "        dataframe[\"std_spectrogram_\" + str(i)] = [np.std(chunk[i]) for chunk in spectrograms]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "df = extract_spectrogram(df)\n",
    "# df_eval = extract_spectrogram(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_chroma(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    chromas = []\n",
    "    for data in dataframe['data']:\n",
    "        # Compute the chroma feature\n",
    "        chroma = librosa.feature.chroma_stft(data)\n",
    "\n",
    "        # Split the chroma into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(chroma, n_chunks)\n",
    "\n",
    "        # Append the chunks to the list of chromas\n",
    "        chromas.append(chunks)\n",
    "\n",
    "    # Add the chroma chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_chroma_\" + str(i)] = [np.mean(chunk[i]) for chunk in chromas]\n",
    "        dataframe[\"std_chroma_\" + str(i)] = [np.std(chunk[i]) for chunk in chromas]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = extract_chroma(df)\n",
    "df_eval = extract_chroma(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_tonnetz(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    tonnetzs = []\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "\n",
    "        # Compute the tonnetz\n",
    "        tonnetz = librosa.feature.tonnetz(y=data, sr=rate)\n",
    "\n",
    "        # Split the tonnetz into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(tonnetz, n_chunks)\n",
    "\n",
    "        # Append the chunks to the list of tonnetzs\n",
    "        tonnetzs.append(chunks)\n",
    "\n",
    "    # Add the tonnetz chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_tonnetz_\" + str(i)] = [np.mean(chunk[i]) for chunk in tonnetzs]\n",
    "        dataframe[\"std_tonnetz_\" + str(i)] = [np.std(chunk[i]) for chunk in tonnetzs]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_spectral_contrast(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    spectral_contrasts = []\n",
    "    for data in dataframe['data']:\n",
    "        # Compute the spectral contrast\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(data)\n",
    "\n",
    "        # Split the spectral contrast into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(spectral_contrast, n_chunks)\n",
    "\n",
    "        # Append the chunks to the list of spectral_contrasts\n",
    "        spectral_contrasts.append(chunks)\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_spectral_contrast_\" + str(i)] = [np.mean(chunk[i]) for chunk in spectral_contrasts]\n",
    "        dataframe[\"std_spectral_contrast_\" + str(i)] = [np.std(chunk[i]) for chunk in spectral_contrasts]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = extract_spectral_contrast(df)\n",
    "df_eval = extract_spectral_contrast(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_spectral_contrast(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    spectral_contrasts = []\n",
    "    for data in dataframe['data']:\n",
    "\n",
    "        # Compute the spectral contrast\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(data)\n",
    "\n",
    "        # Split the spectral contrast into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(spectral_contrast, n_chunks)\n",
    "\n",
    "        # Append the chunks to the list of spectral contrasts\n",
    "        spectral_contrasts.append(chunks)\n",
    "\n",
    "    # Add the spectral contrast chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_spectral_contrast_\" + str(i)] = [np.mean(chunk[i]) for chunk in spectral_contrasts]\n",
    "        dataframe[\"std_spectral_contrast_\" + str(i)] = [np.std(chunk[i]) for chunk in spectral_contrasts]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = extract_spectral_contrast(df)\n",
    "df_eval = extract_spectral_contrast(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_rms(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    rms = []\n",
    "    for data in dataframe['data']:\n",
    "        # Compute the RMS\n",
    "        rms_data = librosa.feature.rms(data)[0]\n",
    "        # Split the RMS into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(rms_data, n_chunks)\n",
    "        # Append the chunks to the list of RMS\n",
    "        rms.append(chunks)\n",
    "    # Add the RMS chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_rms_\" + str(i)] = [np.mean(chunk[i]) for chunk in rms]\n",
    "        dataframe[\"std_rms_\" + str(i)] = [np.std(chunk[i]) for chunk in rms]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = extract_rms(df)\n",
    "df_eval = extract_rms(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_mfcc(dataframe):\n",
    "    audio_paths = dataframe[\"path\"].values\n",
    "    mfccs = []\n",
    "    for data in dataframe['data']:\n",
    "            # Compute the MFCCs\n",
    "        mfcc = librosa.feature.mfcc(data)\n",
    "\n",
    "        # Split the MFCCs into 20 chunks\n",
    "        n_chunks = 20\n",
    "        chunks = np.array_split(mfcc, n_chunks, axis = 1)\n",
    "\n",
    "        # Append the chunks to the list of MFCCs\n",
    "        mfccs.append(chunks)\n",
    "\n",
    "    # Add the MFCC chunks to the dataframe as new columns\n",
    "    for i in range(n_chunks):\n",
    "        dataframe[\"mean_mfcc_\" + str(i)] = [np.mean(chunk[i]) for chunk in mfccs]\n",
    "        dataframe[\"std_mfcc_\" + str(i)] = [np.std(chunk[i]) for chunk in mfccs]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = extract_mfcc(df)\n",
    "df_eval = extract_mfcc(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over each column in the DataFrame\n",
    "for col in df.columns:\n",
    "    # Check if the column contains 1D or 2D arrays\n",
    "    if isinstance(df[col].values[0], (list, np.ndarray)) and len(df[col].values[0]) > 1:\n",
    "        # Drop the column if it contains 1D or 2D arrays\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "for col in df_eval.columns:\n",
    "    # Check if the column contains 1D or 2D arrays\n",
    "    if isinstance(df_eval[col].values[0], (list, np.ndarray)) and len(df_eval[col].values[0]) > 1:\n",
    "        # Drop the column if it contains 1D or 2D arrays\n",
    "        df_eval.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def drop_nan_columns(df):\n",
    "    df.dropna(axis=1, how='any', inplace=True)\n",
    "    return df\n",
    "drop_nan_columns(df)\n",
    "drop_nan_columns(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "X_eval = df_eval.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# X = pd.read_csv('new_df.csv')\n",
    "# X_eval = pd.read_csv('new_df_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X.drop(columns=['path','speakerId','rate'],inplace=True)\n",
    "X_eval.drop(columns=['path','speakerId','rate'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# X =  normalize_dataframe(X)\n",
    "# X_eval = normalize_dataframe(X_eval)\n",
    "def standardize(x_train, x_test):\n",
    "    mean = np.mean(x_train, axis=0)\n",
    "    std = np.std(x_train, axis=0)\n",
    "    x_train_standardized = (x_train - mean) / std\n",
    "    x_test_standardized = (x_test - mean) / std\n",
    "    return x_train_standardized, x_test_standardized\n",
    "X, X_eval = standardize(X, X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# top_n_features = select_top_n_features(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def new_svm_model(X_train, y_train, X_test):\n",
    "    clf = SVC(kernel = 'rbf', C=10, gamma='auto')\n",
    "    # train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # predict the target values for the test data\n",
    "    # returning the y_predict\n",
    "    return clf.predict(X_test)\n",
    "y_pred = new_svm_model(X, y, X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "key_mapping = np.vectorize(lambda x: next(key for key, value in dict.items() if value == x))\n",
    "keys_arr = key_mapping(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_evaluation_df = pd.DataFrame(keys_arr, columns = ['Predicted'])\n",
    "y_evaluation_df.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = int(time.time())\n",
    "readable_time = datetime.fromtimestamp(now).strftime('%H:%M:%S')\n",
    "y_evaluation_df.to_csv(f'evaluation/copy_predictions-{readable_time}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ccc2ef6718a2989112780daffa238f2a5d7e50ea457a5804450be0e592151e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
