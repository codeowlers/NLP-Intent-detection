{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from algorithms import label_encode_columns, svm_model, accuracy_calculator, random_forest_model, array_column_spread, one_hot_encode_columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset using Pandas\n",
    "The data is found in development.csv (development set): a comma-separated values file containing the records from the development set. This portion does have the action and object columns, which you should use to obtain the labels to train and validate your models.\n",
    "The dataset consists in a collection of audio file in a WAV format. \n",
    "\n",
    "Each record is characterized by several attributes. The following is a short description for each of them.\n",
    "- path: the path of the audio file.\n",
    "- speakerId: the id of the speaker.\n",
    "- action: the type of action required through the intent.\n",
    "- object: the device involved by intent.\n",
    "- Self-reported fluency level: the speaking fluency of the speaker.\n",
    "- First Language spoken: the first language spoken by the speaker.\n",
    "- Current language used for work/school: the main language spoken by the speaker during daily activities.\n",
    "- gender: the gender of the speaker.\n",
    "- ageRange: the age range of the speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dsl_data/development.csv\")\n",
    "df_eval = pd.read_csv(\"dsl_data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"dsl_data/development.csv\")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y = df2.values[:,3:5].sum(axis=1)\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y.reshape(-1, 1))\n",
    "y_decoded = enc.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Self-reported fluency level \",\"First Language spoken\", \"Current language used for work/school\", 'gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_encode_columns(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "for column in columns:\n",
    "    encoder = OneHotEncoder()\n",
    "     # Fit and transform the data\n",
    "    encoded_data = encoder.fit_transform(df[[column]])\n",
    "\n",
    "    # Get the feature names\n",
    "    feature_names = encoder.get_feature_names_out([column])\n",
    "\n",
    "    # Create a new DataFrame with the encoded data\n",
    "    encoded_df = pd.DataFrame(encoded_data.toarray(), columns=feature_names)\n",
    "\n",
    "    # Drop the original column\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    #update the dataframe with the encoded dataframe\n",
    "    df = pd.concat([df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_feature_extraction(df):\n",
    "        data_array= []\n",
    "        rate_array = []\n",
    "        for audio in df['path']:\n",
    "                data, rate = librosa.load(audio)\n",
    "                data_array.append(data)\n",
    "                rate_array.append(rate)\n",
    "\n",
    "        df['data'] = data_array\n",
    "        df['rate'] = rate_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feature_extraction(df)\n",
    "audio_feature_extraction(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def time_domain(df, column):\n",
    "    df[f'{column}_mean'] = df[column].apply(lambda x: np.mean(x))\n",
    "    df[f'{column}_min'] = df[column].apply(lambda x: np.min(x))\n",
    "    df[f'{column}_max'] = df[column].apply(lambda x: np.max(x))\n",
    "    df[f'{column}_skew'] = df[column].apply(lambda x: skew(x))\n",
    "    df[f'{column}_kurtosis'] = df[column].apply(lambda x: kurtosis(x))\n",
    "    df[f'{column}_std'] = df[column].apply(lambda x: np.std(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_feature(df):\n",
    "    chroma_array = []\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        chroma = librosa.feature.chroma_stft(y=data, sr=rate)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        chroma_array.append(chroma_mean)\n",
    "\n",
    "    df['chroma'] = chroma_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_feature(df)\n",
    "chroma_feature(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df, 'chroma')\n",
    "time_domain(df_eval, 'chroma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tonnetz feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonnetz_feature(df):\n",
    "    tonnetz_array = []\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        tonnetz = librosa.feature.tonnetz(y=data, sr=rate)\n",
    "        tonnetz_mean = np.mean(tonnetz, axis=1)\n",
    "        tonnetz_array.append(tonnetz_mean)\n",
    "\n",
    "    df['tonnetz'] = tonnetz_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonnetz_feature(df)\n",
    "tonnetz_feature(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df, 'tonnetz')\n",
    "time_domain(df_eval, 'tonnetz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_contrast(df):\n",
    "    spectral_contrast_array = []\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=data, sr=rate)\n",
    "        spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
    "        spectral_contrast_array.append(spectral_contrast_mean)\n",
    "    df['spectral_contrast'] = spectral_contrast_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_contrast(df)\n",
    "spectral_contrast(df_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df,'spectral_contrast')\n",
    "time_domain(df_eval,'spectral_contrast')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Energy(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_feature(df):\n",
    "    # create an empty list to store the RMSE values\n",
    "    rmse_list = []\n",
    "\n",
    "    # iterate through the audio files in the dataset\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        # calculate the root mean square energy\n",
    "        rmse = librosa.feature.rms(y=data)\n",
    "        # append the rmse mean to the rmse_list\n",
    "        rmse_list.append(rmse[0])\n",
    "\n",
    "    # add the rmse_list as a new column to the dataframe\n",
    "    df['rmse'] = rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_feature(df)\n",
    "rmse_feature(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df, 'rmse')\n",
    "time_domain(df_eval, 'rmse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Flatness (SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(df):\n",
    "    # create an empty list to store the SF values\n",
    "    sf_list = []\n",
    "\n",
    "    # iterate through the audio files in the dataset\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        # calculate the spectral flatness\n",
    "        sf = librosa.feature.spectral_flatness(y=data)\n",
    "        # append the SF mean to the sf_list\n",
    "        sf_list.append(sf[0])\n",
    "\n",
    "    # add the sf_list as a new column to the dataframe\n",
    "    df['sf'] = sf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_flatness(df)\n",
    "spectral_flatness(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df,'sf')\n",
    "time_domain(df_eval,'sf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Roll-off (SRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sro_feature(df):\n",
    "    # Create an empty list to store the spectral roll-off values\n",
    "    spectral_rolloff_array = []\n",
    "\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=rate)\n",
    "        spectral_rolloff_array.append(spectral_rolloff[0])\n",
    "\n",
    "    # Add the spectral roll-off values to the dataframe as a new column\n",
    "    df['spectral_rolloff'] = spectral_rolloff_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sro_feature(df)\n",
    "sro_feature(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df,'spectral_rolloff')\n",
    "time_domain(df_eval,'spectral_rolloff')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr_feature(df):\n",
    "    # Create arrays to store the zero-crossing rate values\n",
    "    zero_crossing_rate_array = []\n",
    "\n",
    "    for data in df['data']:\n",
    "        \n",
    "        # Compute the zero-crossing rate for the current audio file\n",
    "        zero_crossing_rate = sum(librosa.zero_crossings(data))\n",
    "        # Append the zero-crossing rate to the zero_crossing_rate_array\n",
    "        zero_crossing_rate_array.append(zero_crossing_rate)\n",
    "\n",
    "    # Add the zero-crossing rate arrays as new columns in the dataframe\n",
    "    df['zero_crossing_rate'] = zero_crossing_rate_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcr_feature(df)\n",
    "zcr_feature(df_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_feature(df):\n",
    "    # Create arrays to store the mfcc rate values\n",
    "    mfcc_array = []\n",
    "\n",
    "    for data, rate in zip(df['data'], df['rate']):\n",
    "        \n",
    "        # Compute the mfccs for the current audio file\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=rate, n_mfcc=50)\n",
    "        # Compute the mean of the mfccs and append it to the mfcc_array\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_array.append(mfcc_mean)\n",
    "\n",
    "    # Add the mfcc as a new column in the dataframe\n",
    "    df['mfcc'] = mfcc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_feature(df)\n",
    "mfcc_feature(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain(df,'mfcc')\n",
    "time_domain(df_eval,'mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    " \n",
    " # Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['ageRange'])\n",
    "# removing the column 'Purchased' from df\n",
    "# as it is of no use now.\n",
    "df.drop('ageRange', axis=1, inplace=True)\n",
    "    \n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'Purchased'\n",
    "df['ageRange'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features = [ 'ageRange',\n",
    "       'Self-reported fluency level _advanced',\n",
    "       'Self-reported fluency level _basic',\n",
    "       'Self-reported fluency level _intermediate',\n",
    "       'Self-reported fluency level _native',\n",
    "       'First Language spoken_English (Canada)',\n",
    "       'First Language spoken_English (United States)',\n",
    "       'First Language spoken_French (Canada)',\n",
    "       'First Language spoken_Spanish (Venezuela)',\n",
    "       'First Language spoken_Telugu',\n",
    "       'Current language used for work/school_English (Australia)',\n",
    "       'Current language used for work/school_English (Canada)',\n",
    "       'Current language used for work/school_English (United States)',\n",
    "       'Current language used for work/school_Spanish (Venezuela)',\n",
    "       'gender_female', 'gender_male', 'chroma_mean',\n",
    "       'chroma_min', 'chroma_max', 'chroma_skew', 'chroma_kurtosis',\n",
    "       'chroma_std','tonnetz_mean', 'tonnetz_min', 'tonnetz_max',\n",
    "       'tonnetz_skew', 'tonnetz_kurtosis', 'tonnetz_std',\n",
    "       'spectral_contrast_mean', 'spectral_contrast_min',\n",
    "       'spectral_contrast_max', 'spectral_contrast_skew',\n",
    "       'spectral_contrast_kurtosis', 'spectral_contrast_std',\n",
    "       'rmse_mean', 'rmse_min', 'rmse_max', 'rmse_skew', 'rmse_kurtosis',\n",
    "       'rmse_std','sf_mean', 'sf_min', 'sf_max', 'sf_skew',\n",
    "       'sf_kurtosis', 'sf_std','spectral_rolloff_mean',\n",
    "       'spectral_rolloff_min', 'spectral_rolloff_max', 'spectral_rolloff_skew',\n",
    "       'spectral_rolloff_kurtosis', 'spectral_rolloff_std',\n",
    "       'zero_crossing_rate', 'mfcc_mean', 'mfcc_min', 'mfcc_max',\n",
    "       'mfcc_skew', 'mfcc_kurtosis', 'mfcc_std']\n",
    "\n",
    "\n",
    "len(features)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = df_eval[features].copy()\n",
    "X_eval\n",
    "\n",
    "X_eval.to_csv('x_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].copy()\n",
    "X\n",
    "X.to_csv('x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = pd.get_dummies(y_decoded.flatten())\n",
    "y_encoded = y_encoded.values.ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Set the number of features to select\n",
    "k = 10\n",
    "\n",
    "# Create a SelectKBest object\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "\n",
    "# Fit the selector to the data and get the selected features\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadiibrahim/Dev/POLITO/DSL-Project/NLP-Intent-detection/venv/lib/python3.10/site-packages/sklearn/feature_selection/_base.py:96: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier object\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Create a SelectFromModel object and specify the threshold\n",
    "selector = SelectFromModel(clf, threshold=0.25)\n",
    "\n",
    "# Fit the selector to the data and get the selected features\n",
    "X_new = selector.fit_transform(X, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(9854, 0), dtype=float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Set the number of features to select\n",
    "n_features = 10\n",
    "\n",
    "# Create an SVR object\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "# Create an RFE object\n",
    "selector = RFE(estimator, n_features_to_select=n_features)\n",
    "\n",
    "# Fit the RFE object to the data and get the selected features\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set the number of features to select\n",
    "n_features = 10\n",
    "\n",
    "# Create an RandomForestClassifier object\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Create an RFE object\n",
    "selector = RFE(estimator, n_features_to_select=n_features)\n",
    "\n",
    "# Fit the RFE object to the data and get the selected features\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Set the threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Create a VarianceThreshold object\n",
    "selector = VarianceThreshold(threshold)\n",
    "\n",
    "# Fit the selector to the data and get the selected features\n",
    "X_new = selector.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Set the number of components\n",
    "n_components = 10\n",
    "\n",
    "# Create a PCA object\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit the PCA to the data and get the selected features\n",
    "X_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "original_cols = df_scaled.columns[pca.components_[:n_components].argmax(axis=1)]\n",
    "\n",
    "# Create a new dataframe with the top n features\n",
    "top_n_features = pd.DataFrame(X_pca, columns=original_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9854 9854\n"
     ]
    }
   ],
   "source": [
    "print(len(y_encoded), len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# One-hot encode the y variable\n",
    "y_encoded = pd.get_dummies(y_decoded)\n",
    "\n",
    "# Check the shape of y_encoded\n",
    "print(y_encoded.shape)\n",
    "\n",
    "# Check the shape of X\n",
    "print(X.shape)\n",
    "\n",
    "# Flatten y_encoded to 1D array with the same dimensionality as X\n",
    "y_encoded = y_encoded.values.ravel()\n",
    "\n",
    "# check the shape of y_encoded after flatten\n",
    "print(y_encoded.shape)\n",
    "\n",
    "# Create an SVR object\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "# Create an RFE object and specify the number of features to select\n",
    "selector = RFE(estimator, n_features_to_select=20)\n",
    "\n",
    "# Fit the RFE object to the data and get the selected features\n",
    "X_new = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "# Get the selected feature names\n",
    "feature_names = X.columns[selector.get_support()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadiibrahim/Dev/POLITO/DSL-Project/NLP-Intent-detection/venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "y_labeled = label_encoder.fit_transform(y)\n",
    "np.unique(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(top_n_features, y_labeled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval = svm_model(X, y, X_eval)\n",
    "\n",
    "predictions = pd.DataFrame(y_pred_eval,columns=[\"Predicted\"])\n",
    "predictions.to_csv('my_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def svm_model2(X_train, y_train, X_test):\n",
    "    clf = SVC(C=0.1, kernel='linear', gamma=0.1)\n",
    "    # train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # predict the target values for the test data\n",
    "    # returning the y_predict\n",
    "    return clf.predict(X_test)\n",
    "y_pred = svm_model2(X_train, y_train, X_test)\n",
    "svm_accuracy = accuracy_calculator(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 3, ..., 5, 1, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval = random_forest_model(X , X_eval, y)\n",
    "\n",
    "predictions = pd.DataFrame(y_pred_eval,columns=[\"Predicted\"])\n",
    "predictions.to_csv('predictions.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest_model(X_train, X_test, y_train)\n",
    "random_forest_accuracy = accuracy_calculator(y_test, y_pred)\n",
    "random_forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "## Implementation using k-fold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# define the number of folds and whether to shuffle the data\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# create an instance of the SVM model\n",
    "clf = SVC()\n",
    "\n",
    "# use cross_val_score function to perform k-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y_labeled, cv=kf, scoring='accuracy')\n",
    "\n",
    "# print the mean accuracy and standard deviation\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# shuffle the data before performing k-fold cross validation\n",
    "X, y = shuffle(X, y_encoded)\n",
    "\n",
    "# perform k-fold cross validation with 5 folds\n",
    "scores = cross_val_score(clf, X, y_encoded, cv=5)\n",
    "\n",
    "# calculate the mean accuracy of the model across all folds\n",
    "accuracy = np.mean(scores)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ccc2ef6718a2989112780daffa238f2a5d7e50ea457a5804450be0e592151e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
