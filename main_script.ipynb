{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, GRU, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from algorithms import *\n",
    "from scipy.stats import skew, kurtosis\n",
    "import noisereduce as nr\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract development and evaluation\n",
    "df = pd.read_csv(\"dsl_data/development.csv\")\n",
    "df_eval = pd.read_csv(\"dsl_data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder(df, 'gender')\n",
    "label_encoder(df_eval, 'gender')\n",
    "label_encoder(df, 'ageRange')\n",
    "label_encoder(df_eval, 'ageRange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "condition = (df['Current language used for work/school'] == np.unique(df_eval['Current language used for work/school'].values)[0]) & (df['First Language spoken'] == np.unique(df_eval['First Language spoken'].values)[0]) & (df['Self-reported fluency level '] == np.unique(df_eval['Self-reported fluency level '].values)[0]) & (df['ageRange'] == np.unique(df_eval['ageRange'].values)[0])\n",
    "df = df.loc[condition]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['Id','Self-reported fluency level ', 'First Language spoken', 'Current language used for work/school']\n",
    "df.drop(columns=cols,inplace=True)\n",
    "df_eval.drop(columns=cols[:4],inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(df):\n",
    "        # Extract features for each audio\n",
    "    for index,row in df.iterrows():\n",
    "        y_untrimmed, sr = librosa.load(row[\"path\"], mono=True)\n",
    "        y_trimmed, i = librosa.effects.trim(y_untrimmed, top_db=30, frame_length=2048, hop_length=512)\n",
    "        y_noise_reduced = nr.reduce_noise(y=y_trimmed, sr=sr)\n",
    "        extracted_duration = librosa.get_duration(y=y_noise_reduced, sr=sr)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y_noise_reduced, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y_noise_reduced)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y_noise_reduced, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y_noise_reduced, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y_noise_reduced, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y= y_noise_reduced)\n",
    "        mfcc = librosa.feature.mfcc(y=y_noise_reduced, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(y=y_noise_reduced, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y_noise_reduced, sr=sr)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y_noise_reduced, sr=sr)\n",
    "\n",
    "        df.at[index, \"audio_duration\"] = extracted_duration\n",
    "        # Fill in the features for each audio\n",
    "        df.at[index, \"chroma_stft_mean\"] = np.mean(chroma_stft)\n",
    "        df.at[index, \"chroma_stft_std\"] = np.std(chroma_stft)\n",
    "        df.at[index, \"chroma_stft_min\"] = np.min(chroma_stft)\n",
    "        df.at[index, \"chroma_stft_max\"] = np.max(chroma_stft)\n",
    "\n",
    "        df.at[index, \"rmse_mean\"] = np.mean(rmse)\n",
    "        df.at[index, \"rmse_std\"] = np.std(rmse)\n",
    "        df.at[index, \"rmse_min\"] = np.min(rmse)\n",
    "        df.at[index, \"rmse_max\"] = np.max(rmse)\n",
    "\n",
    "        df.at[index, \"spectral_centroid_mean\"] = np.mean(spec_cent)\n",
    "        df.at[index, \"spectral_centroid_std\"] = np.std(spec_cent)\n",
    "        df.at[index, \"spectral_centroid_min\"] = np.min(spec_cent)\n",
    "        df.at[index, \"spectral_centroid_max\"] = np.max(spec_cent)\n",
    "\n",
    "        df.at[index, \"spectral_bandwidth_mean\"] = np.mean(spec_bw)\n",
    "        df.at[index, \"spectral_bandwidth_std\"] = np.std(spec_bw)\n",
    "        df.at[index, \"spectral_bandwidth_min\"] = np.min(spec_bw)\n",
    "        df.at[index, \"spectral_bandwidth_max\"] = np.max(spec_bw)\n",
    "        \n",
    "        df.at[index, \"rolloff_mean\"] = np.mean(rolloff)\n",
    "        df.at[index, \"rolloff__std\"] = np.std(rolloff)\n",
    "        df.at[index, \"rolloff_min\"] = np.min(rolloff)\n",
    "        df.at[index, \"rolloff_max\"] = np.max(rolloff)\n",
    "\n",
    "        df.at[index, \"zero_crossing_rate_mean\"] = np.mean(zcr)\n",
    "        df.at[index, \"zero_crossing_rate_std\"] = np.std(zcr)\n",
    "        df.at[index, \"zero_crossing_rate_min\"] = np.min(zcr)\n",
    "        df.at[index, \"zero_crossing_rate_max\"] = np.max(zcr)\n",
    "\n",
    "        for i in range(len(mfcc)):\n",
    "            df.at[index, f\"mfcc_mean{i + 1}\"] = np.mean(mfcc[i])\n",
    "            df.at[index, f\"mfcc_std{i + 1}\"] = np.std(mfcc[i])\n",
    "            df.at[index, f\"mfcc_min{i + 1}\"] = np.min(mfcc[i])\n",
    "            df.at[index, f\"mfcc_max{i + 1}\"] = np.max(mfcc[i])\n",
    "            df.at[index, f\"mfcc_skew{i + 1}\"] = skew(mfcc[i])\n",
    "            df.at[index, f\"mfcc_kurtosis{i + 1}\"] = kurtosis(mfcc[i])\n",
    "            \n",
    "\n",
    "        for i in range(len(tonnetz)):\n",
    "            df.at[index, f\"tonnetz_mean{i + 1}\"] = np.mean(tonnetz[i])\n",
    "            df.at[index, f\"tonnetz_std{i + 1}\"] = np.std(tonnetz[i])\n",
    "            df.at[index, f\"tonnetz_min{i + 1}\"] = np.min(tonnetz[i])\n",
    "            df.at[index, f\"tonnetz_max{i + 1}\"] = np.max(tonnetz[i])\n",
    "            df.at[index, f\"tonnetz_skew{i + 1}\"] = skew(tonnetz[i])\n",
    "            df.at[index, f\"tonnetz_kurtosis{i + 1}\"] = kurtosis(tonnetz[i])\n",
    "\n",
    "\n",
    "        for i in range(len(spectral_contrast)):\n",
    "            df.at[index, f\"spectral_contrast_mean{i + 1}\"] = np.mean(spectral_contrast[i])\n",
    "            df.at[index, f\"spectral_contrast_std{i + 1}\"] = np.std(spectral_contrast[i])\n",
    "            df.at[index, f\"spectral_contrast_min{i + 1}\"] = np.min(spectral_contrast[i])\n",
    "            df.at[index, f\"spectral_contrast_max{i + 1}\"] = np.max(spectral_contrast[i])\n",
    "            df.at[index, f\"spectral_contrast_skew{i + 1}\"] = skew(spectral_contrast[i])\n",
    "            df.at[index, f\"spectral_contrast_kurtosis{i + 1}\"] = kurtosis(spectral_contrast[i])\n",
    "\n",
    "\n",
    "        for i in range(len(chroma_stft)):\n",
    "            df.at[index, f\"chroma_stft_mean{i + 1}\"] = np.mean(chroma_stft[i])\n",
    "            df.at[index, f\"chroma_stft_std{i + 1}\"] = np.std(chroma_stft[i])\n",
    "            df.at[index, f\"chroma_stft_min{i + 1}\"] = np.min(chroma_stft[i])\n",
    "            df.at[index, f\"chroma_stft_max{i + 1}\"] = np.max(chroma_stft[i])\n",
    "            df.at[index, f\"chroma_stft_skew{i + 1}\"] = skew(chroma_stft[i])\n",
    "            df.at[index, f\"chroma_stft_kurtosis{i + 1}\"] = kurtosis(chroma_stft[i])\n",
    "\n",
    "        for i in range(len(spectrogram)):\n",
    "            df.at[index, f\"spectogram_mean{i + 1}\"] = np.mean(spectrogram[i])\n",
    "            df.at[index, f\"spectogram_std{i + 1}\"] = np.std(spectrogram[i])\n",
    "            df.at[index, f\"spectogram_min{i + 1}\"] = np.min(spectrogram[i])\n",
    "            df.at[index, f\"spectogram_max{i + 1}\"] = np.max(spectrogram[i])\n",
    "            df.at[index, f\"spectogram_skew{i + 1}\"] = skew(spectrogram[i])\n",
    "            df.at[index, f\"spectogram_kurtosis{i + 1}\"] = kurtosis(spectrogram[i])\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"df.pkl\"):\n",
    "    with open('df.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    with open('df_eval.pkl', 'rb') as f:\n",
    "        df_eval = pickle.load(f)\n",
    "else:\n",
    "    df = extract_all_features(df)\n",
    "    df_eval = extract_all_features(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = df['action']+ df['object']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['path', 'speakerId','action','object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(X, dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = df_eval.drop(columns=['path', 'speakerId' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_eval = normalize_dataframe(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = scaler.fit_transform(np.array(X_eval, dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(X.shape[1],), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(y), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X,\n",
    "                    y,\n",
    "                    epochs=100,\n",
    "                    batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy history\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "# print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = predictions.argmax(axis=-1)\n",
    "\n",
    "# Convert the predicted class labels back to the original target classes\n",
    "y_pred_classes_decoded = encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Convert the decoded predictions to a pandas Series\n",
    "y_pred_classes_decoded = pd.Series(y_pred_classes_decoded, name='Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "y_evaluation_df = pd.DataFrame(y_pred_classes_decoded, columns = ['Predicted'])\n",
    "y_evaluation_df.index.name = 'Id'\n",
    "\n",
    "from datetime import datetime\n",
    "now = int(time.time())\n",
    "readable_time = datetime.fromtimestamp(now).strftime('%H:%M:%S')\n",
    "y_evaluation_df.to_csv(f'evaluation/copy_predictions-{readable_time}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, X_test, le):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "#     y_pred_labels = le.inverse_transform(y_pred_classes)\n",
    "#     y_pred_labels = pd.Series(y_pred_labels)\n",
    "#     return y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"df.pkl\"):\n",
    "    with open('df.pkl', 'rb') as f:\n",
    "        pickle.dump(df, f)\n",
    "    with open('df_eval.pkl', 'rb') as f:\n",
    "        pickle.dump(df_eval, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09ee11da7dc62f10eaf9df9c4559184832adcd88d836286cbf9804f9d006cf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
